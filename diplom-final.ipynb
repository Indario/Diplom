{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7e0285",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-06-07T20:17:49.994774Z",
     "iopub.status.busy": "2023-06-07T20:17:49.994248Z",
     "iopub.status.idle": "2023-06-07T20:18:04.604239Z",
     "shell.execute_reply": "2023-06-07T20:18:04.603306Z"
    },
    "papermill": {
     "duration": 14.623579,
     "end_time": "2023-06-07T20:18:04.606774",
     "exception": false,
     "start_time": "2023-06-07T20:17:49.983195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tokenizers\n",
    "import string\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5b4380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:04.626845Z",
     "iopub.status.busy": "2023-06-07T20:18:04.626472Z",
     "iopub.status.idle": "2023-06-07T20:18:04.646669Z",
     "shell.execute_reply": "2023-06-07T20:18:04.645515Z"
    },
    "papermill": {
     "duration": 0.033103,
     "end_time": "2023-06-07T20:18:04.649040",
     "exception": false,
     "start_time": "2023-06-07T20:18:04.615937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            print('Max score is {}'.format(self.best_score))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score\n",
    "        \n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    #_, start_positions = torch.max(start_positions, 1)\n",
    "    #_, end_positions = torch.max(end_positions, 1)\n",
    "    #print(start_logits, start_positions)\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    return total_loss\n",
    "def optimizer_params(model):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    return optimizer_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b521431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:04.668086Z",
     "iopub.status.busy": "2023-06-07T20:18:04.667680Z",
     "iopub.status.idle": "2023-06-07T20:18:04.846144Z",
     "shell.execute_reply": "2023-06-07T20:18:04.845153Z"
    },
    "papermill": {
     "duration": 0.191282,
     "end_time": "2023-06-07T20:18:04.848910",
     "exception": false,
     "start_time": "2023-06-07T20:18:04.657628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "DATA_PATH = \"../input/tweetsentanalys\"\n",
    "#BERT_PATH = \"../input/bert-base-uncased\"\n",
    "#TOKENIZER = tokenizers.BertWordPieceTokenizer(\n",
    "#    os.path.join(BERT_PATH, \"vocab.txt\"),\n",
    "#    lowercase=True\n",
    "#)\n",
    "\n",
    "\n",
    "ROBERTA_PATH = \"../input/roberta-base-my\"\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "    merges=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "\n",
    "model_config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH)\n",
    "model_config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1e35da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:04.868771Z",
     "iopub.status.busy": "2023-06-07T20:18:04.868329Z",
     "iopub.status.idle": "2023-06-07T20:18:05.040711Z",
     "shell.execute_reply": "2023-06-07T20:18:05.039843Z"
    },
    "papermill": {
     "duration": 0.185392,
     "end_time": "2023-06-07T20:18:05.043351",
     "exception": false,
     "start_time": "2023-06-07T20:18:04.857959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5586dbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.065113Z",
     "iopub.status.busy": "2023-06-07T20:18:05.064165Z",
     "iopub.status.idle": "2023-06-07T20:18:05.093635Z",
     "shell.execute_reply": "2023-06-07T20:18:05.092650Z"
    },
    "papermill": {
     "duration": 0.042314,
     "end_time": "2023-06-07T20:18:05.096214",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.053900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0a8f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.116676Z",
     "iopub.status.busy": "2023-06-07T20:18:05.115930Z",
     "iopub.status.idle": "2023-06-07T20:18:05.137664Z",
     "shell.execute_reply": "2023-06-07T20:18:05.136506Z"
    },
    "papermill": {
     "duration": 0.034791,
     "end_time": "2023-06-07T20:18:05.140299",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.105508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    tweet = \" \" + \" \".join(str(tweet).split())\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 4\n",
    "    targets_end += 4\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }\n",
    "\n",
    "\n",
    "class TweetDataset:\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item], \n",
    "            self.selected_text[item], \n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2059167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.161186Z",
     "iopub.status.busy": "2023-06-07T20:18:05.160372Z",
     "iopub.status.idle": "2023-06-07T20:18:05.170244Z",
     "shell.execute_reply": "2023-06-07T20:18:05.169469Z"
    },
    "papermill": {
     "duration": 0.023121,
     "end_time": "2023-06-07T20:18:05.172655",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.149534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class BERTBaseUncased(transformers.BertPreTrainedModel):\n",
    "    def __init__(self):\n",
    "        super(BERTBaseUncased, self).__init__(model_config)\n",
    "        #self.bert = transformers.BertModel.from_pretrained(BERT_PATH, config=model_config)\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained(ROBERTA_PATH, config=model_config)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.l0 = nn.Linear(2 * 768, 2)\n",
    "        torch.nn.init.normal_(self.l0.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        out = self.roberta(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )[\"hidden_states\"]\n",
    "\n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.drop(out)\n",
    "        logits = self.l0(out)\n",
    "\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfd8b5",
   "metadata": {
    "papermill": {
     "duration": 0.008852,
     "end_time": "2023-06-07T20:18:05.190721",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.181869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e85d51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.211196Z",
     "iopub.status.busy": "2023-06-07T20:18:05.210389Z",
     "iopub.status.idle": "2023-06-07T20:18:05.263962Z",
     "shell.execute_reply": "2023-06-07T20:18:05.263055Z"
    },
    "papermill": {
     "duration": 0.06666,
     "end_time": "2023-06-07T20:18:05.266491",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.199831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna().reset_index(drop=True)\n",
    "\n",
    "train_data, valid_data = model_selection.train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d361ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.286709Z",
     "iopub.status.busy": "2023-06-07T20:18:05.286049Z",
     "iopub.status.idle": "2023-06-07T20:18:05.299364Z",
     "shell.execute_reply": "2023-06-07T20:18:05.298384Z"
    },
    "papermill": {
     "duration": 0.025844,
     "end_time": "2023-06-07T20:18:05.301511",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.275667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_jaccard_score(\n",
    "    original_tweet, \n",
    "    target_string, \n",
    "    sentiment_val, \n",
    "    idx_start, \n",
    "    idx_end, \n",
    "    offsets,\n",
    "    verbose=False):\n",
    "    \n",
    "    if idx_end < idx_start:\n",
    "        idx_end = idx_start\n",
    "    \n",
    "    filtered_output  = \"\"\n",
    "    original_tweet_sp = \" \".join(original_tweet.split())\n",
    "    for ix in range(idx_start, idx_end + 1):\n",
    "        if offsets[ix][0] == 0 and offsets[ix][1] == 0:\n",
    "            continue\n",
    "        filtered_output += original_tweet_sp[offsets[ix][0]: offsets[ix][1]]\n",
    "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
    "            filtered_output += \" \"\n",
    "    filtered_output_kek = f\"{filtered_output}\"\n",
    "    filtered_output = filtered_output.replace(\" .\", \".\")\n",
    "    filtered_output = filtered_output.replace(\" ?\", \"?\")\n",
    "    filtered_output = filtered_output.replace(\" !\", \"!\")\n",
    "    filtered_output = filtered_output.replace(\" ,\", \",\")\n",
    "    filtered_output = filtered_output.replace(\" ' \", \"'\")\n",
    "    filtered_output = filtered_output.replace(\" n't\", \"n't\")\n",
    "    filtered_output = filtered_output.replace(\" 'm\", \"'m\")\n",
    "    filtered_output = filtered_output.replace(\" do not\", \" don't\")\n",
    "    filtered_output = filtered_output.replace(\" 's\", \"'s\")\n",
    "    filtered_output = filtered_output.replace(\" 've\", \"'ve\")\n",
    "    filtered_output = filtered_output.replace(\" 're\", \"'re\")\n",
    "\n",
    "    if verbose == True:\n",
    "        if filtered_output.strip().lower() != target_string.strip().lower():\n",
    "            print(\"********************************\")\n",
    "            print(f\"Output= {filtered_output.strip()}\")\n",
    "            print(f\"Target= {target_string.strip()}\")\n",
    "            print(f\"Tweet= {original_tweet.strip()}\")\n",
    "            print(\"********************************\")\n",
    "\n",
    "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
    "    return jac, filtered_output_kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0866da8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.322197Z",
     "iopub.status.busy": "2023-06-07T20:18:05.321471Z",
     "iopub.status.idle": "2023-06-07T20:18:05.335441Z",
     "shell.execute_reply": "2023-06-07T20:18:05.334657Z"
    },
    "papermill": {
     "duration": 0.027066,
     "end_time": "2023-06-07T20:18:05.337877",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.310811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for d in tk0:\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        model.zero_grad()\n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            jaccard_score, _ = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                sentiment_val=sentiment,\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "\n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8726129d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.358326Z",
     "iopub.status.busy": "2023-06-07T20:18:05.357639Z",
     "iopub.status.idle": "2023-06-07T20:18:05.371017Z",
     "shell.execute_reply": "2023-06-07T20:18:05.370247Z"
    },
    "papermill": {
     "duration": 0.026308,
     "end_time": "2023-06-07T20:18:05.373348",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.347040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_fn(valid_loader, model, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(valid_loader, total=len(valid_loader))\n",
    "        for d in tk0:\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            offsets = d[\"offsets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_start, outputs_end = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            jaccard_scores = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                jaccard_score, _ = calculate_jaccard_score(\n",
    "                    original_tweet=tweet,\n",
    "                    target_string=selected_tweet,\n",
    "                    idx_start=np.argmax(outputs_start[px, :]),\n",
    "                    idx_end=np.argmax(outputs_end[px, :]),\n",
    "                    sentiment_val=sentiment,\n",
    "                    offsets=offsets[px]\n",
    "                )\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "\n",
    "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "    print(f\"Jaccard = {jaccards.avg}\")\n",
    "    return jaccards.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d7638",
   "metadata": {
    "papermill": {
     "duration": 0.008802,
     "end_time": "2023-06-07T20:18:05.391388",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.382586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd8a404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.411414Z",
     "iopub.status.busy": "2023-06-07T20:18:05.410826Z",
     "iopub.status.idle": "2023-06-07T20:18:05.420740Z",
     "shell.execute_reply": "2023-06-07T20:18:05.419851Z"
    },
    "papermill": {
     "duration": 0.0227,
     "end_time": "2023-06-07T20:18:05.423067",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.400367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(model, device, train_data, val_data, label, lr=5e-3):\n",
    "    train_dataset = TweetDataset(\n",
    "        tweet=train_data.text.values,\n",
    "        sentiment=train_data.sentiment.values,\n",
    "        selected_text=train_data.selected_text.values\n",
    "    )\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "    )\n",
    "    \n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet=val_data.text.values,\n",
    "        sentiment=val_data.sentiment.values,\n",
    "        selected_text=val_data.selected_text.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "    optimizer =  transformers.AdamW(optimizer_params(model), lr=lr)\n",
    "    #optimizer =  transformers.AdamW(model.parameters(), lr=lr)\n",
    "    #scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    #    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    "    #)\n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    "    )\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "    print(\"Training is Starting\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "        jaccard = eval_fn(valid_data_loader, model, device)\n",
    "        print(f\"Jaccard Score = {jaccard}\")\n",
    "        es(jaccard, model, model_path=f\"model_{label}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23d5775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.443295Z",
     "iopub.status.busy": "2023-06-07T20:18:05.442443Z",
     "iopub.status.idle": "2023-06-07T20:18:05.447221Z",
     "shell.execute_reply": "2023-06-07T20:18:05.446217Z"
    },
    "papermill": {
     "duration": 0.017379,
     "end_time": "2023-06-07T20:18:05.449594",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.432215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29cd9e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:05.469484Z",
     "iopub.status.busy": "2023-06-07T20:18:05.469091Z",
     "iopub.status.idle": "2023-06-07T20:18:11.938487Z",
     "shell.execute_reply": "2023-06-07T20:18:11.937280Z"
    },
    "papermill": {
     "duration": 6.482474,
     "end_time": "2023-06-07T20:18:11.940876",
     "exception": false,
     "start_time": "2023-06-07T20:18:05.458402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base-my were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTBaseUncased(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pos = BERTBaseUncased()\n",
    "model_pos.to(device)\n",
    "#run(model_pos, device, train_data, valid_data, \"main\", 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9eee55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:11.961717Z",
     "iopub.status.busy": "2023-06-07T20:18:11.961277Z",
     "iopub.status.idle": "2023-06-07T20:18:13.053877Z",
     "shell.execute_reply": "2023-06-07T20:18:13.052355Z"
    },
    "papermill": {
     "duration": 1.106483,
     "end_time": "2023-06-07T20:18:13.056852",
     "exception": false,
     "start_time": "2023-06-07T20:18:11.950369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_main_final.bin\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/final-model-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c43f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:13.078852Z",
     "iopub.status.busy": "2023-06-07T20:18:13.077445Z",
     "iopub.status.idle": "2023-06-07T20:18:19.644910Z",
     "shell.execute_reply": "2023-06-07T20:18:19.643856Z"
    },
    "papermill": {
     "duration": 6.581101,
     "end_time": "2023-06-07T20:18:19.647378",
     "exception": false,
     "start_time": "2023-06-07T20:18:13.066277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base-my were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTBaseUncased()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"../input/final-model-roberta/model_main_final.bin\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3821614d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:19.669504Z",
     "iopub.status.busy": "2023-06-07T20:18:19.668419Z",
     "iopub.status.idle": "2023-06-07T20:18:19.678223Z",
     "shell.execute_reply": "2023-06-07T20:18:19.676906Z"
    },
    "papermill": {
     "duration": 0.023565,
     "end_time": "2023-06-07T20:18:19.680714",
     "exception": false,
     "start_time": "2023-06-07T20:18:19.657149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.loc[:, \"selected_text\"] = test_data.text.values\n",
    "final_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f4b5c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:18:19.702244Z",
     "iopub.status.busy": "2023-06-07T20:18:19.701390Z",
     "iopub.status.idle": "2023-06-07T20:30:42.338132Z",
     "shell.execute_reply": "2023-06-07T20:30:42.336741Z"
    },
    "papermill": {
     "duration": 742.64991,
     "end_time": "2023-06-07T20:30:42.340290",
     "exception": false,
     "start_time": "2023-06-07T20:18:19.690380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3534/3534 [12:22<00:00,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataset = TweetDataset(\n",
    "        tweet=test_data.text.values,\n",
    "        sentiment=test_data.sentiment.values,\n",
    "        selected_text=test_data.selected_text.values\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for d in tk0:\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            _, output_sentence = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                sentiment_val=sentiment,\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            final_output.append(output_sentence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1e570",
   "metadata": {
    "papermill": {
     "duration": 0.321029,
     "end_time": "2023-06-07T20:30:42.980109",
     "exception": false,
     "start_time": "2023-06-07T20:30:42.659080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58e5da66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:30:43.687908Z",
     "iopub.status.busy": "2023-06-07T20:30:43.687138Z",
     "iopub.status.idle": "2023-06-07T20:30:43.741871Z",
     "shell.execute_reply": "2023-06-07T20:30:43.740734Z"
    },
    "papermill": {
     "duration": 0.44538,
     "end_time": "2023-06-07T20:30:43.744407",
     "exception": false,
     "start_time": "2023-06-07T20:30:43.299027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../input/tweetsentanalys/sample_submission.csv\")\n",
    "sample.loc[:, 'selected_text'] = final_output\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13ab5088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T20:30:44.384511Z",
     "iopub.status.busy": "2023-06-07T20:30:44.384027Z",
     "iopub.status.idle": "2023-06-07T20:30:44.394889Z",
     "shell.execute_reply": "2023-06-07T20:30:44.393883Z"
    },
    "papermill": {
     "duration": 0.333258,
     "end_time": "2023-06-07T20:30:44.397031",
     "exception": false,
     "start_time": "2023-06-07T20:30:44.063773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>such a shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                     selected_text\n",
       "0  f87dea47db  Last session of the day http://twitpic.com/67ezh\n",
       "1  96d74cb729                                         exciting \n",
       "2  eee518ae67                                     such a shame!\n",
       "3  01082688c6                                       happy bday!\n",
       "4  33987a8ee5                                       I like it!!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bbe92",
   "metadata": {
    "papermill": {
     "duration": 0.320545,
     "end_time": "2023-06-07T20:30:45.035077",
     "exception": false,
     "start_time": "2023-06-07T20:30:44.714532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c0527",
   "metadata": {
    "papermill": {
     "duration": 0.320542,
     "end_time": "2023-06-07T20:30:45.677388",
     "exception": false,
     "start_time": "2023-06-07T20:30:45.356846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b4d91",
   "metadata": {
    "papermill": {
     "duration": 0.318711,
     "end_time": "2023-06-07T20:30:46.317022",
     "exception": false,
     "start_time": "2023-06-07T20:30:45.998311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a662e2",
   "metadata": {
    "papermill": {
     "duration": 0.31821,
     "end_time": "2023-06-07T20:30:47.020709",
     "exception": false,
     "start_time": "2023-06-07T20:30:46.702499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 792.102106,
   "end_time": "2023-06-07T20:30:50.786876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-07T20:17:38.684770",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
